name: Airflow ML Pipeline CI/CD

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

env:
  PYTHON_VERSION: '3.10'
  AIRFLOW_VERSION: '2.7.3'

jobs:
  lint-and-test:
    name: Lint and Test
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Cache pip packages
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install apache-airflow==${{ env.AIRFLOW_VERSION }}
        pip install pandas scikit-learn numpy pytest flake8 pylint
    
    - name: Lint with flake8
      run: |
        # Stop the build if there are Python syntax errors or undefined names
        flake8 dags/ --count --select=E9,F63,F7,F82 --show-source --statistics
        # Exit-zero treats all errors as warnings
        flake8 dags/ --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
    
    - name: Test DAG integrity
      run: |
        python -c "
        import sys
        sys.path.insert(0, 'dags')
        from iris_ml_pipeline import dag
        print('âœ“ DAG loaded successfully')
        print(f'âœ“ DAG ID: {dag.dag_id}')
        print(f'âœ“ Tasks: {len(dag.tasks)}')
        assert dag.dag_id == 'iris_ml_pipeline'
        assert len(dag.tasks) > 0
        print('âœ… All DAG integrity tests passed!')
        "
    
    - name: Validate DAG structure
      run: |
        python -c "
        import sys
        sys.path.insert(0, 'dags')
        from iris_ml_pipeline import dag
        
        # Check for cycles
        assert not dag.test_cycle(), 'DAG has cycles!'
        print('âœ“ No cycles detected')
        
        # Verify task dependencies
        task_ids = [task.task_id for task in dag.tasks]
        print(f'âœ“ Tasks: {task_ids}')
        
        # Check required tasks exist
        required_tasks = [
            'extract_iris_dataset',
            'feature_engineering', 
            'train_models',
            'evaluate_models',
            'deploy_model'
        ]
        for task in required_tasks:
            assert task in task_ids, f'Missing required task: {task}'
        
        print('âœ… DAG structure validation passed!')
        "

  test-pipeline:
    name: Test ML Pipeline
    runs-on: ubuntu-latest
    needs: lint-and-test
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pandas scikit-learn numpy pytest
    
    - name: Test data extraction
      run: |
        python -c "
        from sklearn.datasets import load_iris
        import pandas as pd
        
        iris = load_iris()
        df = pd.DataFrame(iris.data, columns=iris.feature_names)
        df['species'] = iris.target
        
        assert len(df) == 150, 'Expected 150 samples'
        assert len(iris.feature_names) == 4, 'Expected 4 features'
        assert len(set(iris.target)) == 3, 'Expected 3 classes'
        
        print('âœ… Data extraction test passed!')
        "
    
    - name: Test feature engineering
      run: |
        python -c "
        from sklearn.datasets import load_iris
        import pandas as pd
        
        iris = load_iris()
        df = pd.DataFrame(iris.data, columns=iris.feature_names)
        
        # Test feature creation
        df['petal_area'] = df['petal length (cm)'] * df['petal width (cm)']
        df['sepal_area'] = df['sepal length (cm)'] * df['sepal width (cm)']
        
        assert 'petal_area' in df.columns
        assert 'sepal_area' in df.columns
        assert df['petal_area'].isna().sum() == 0
        
        print('âœ… Feature engineering test passed!')
        "
    
    - name: Test model training
      run: |
        python -c "
        from sklearn.datasets import load_iris
        from sklearn.model_selection import train_test_split
        from sklearn.ensemble import RandomForestClassifier
        from sklearn.metrics import accuracy_score
        
        iris = load_iris()
        X_train, X_test, y_train, y_test = train_test_split(
            iris.data, iris.target, test_size=0.2, random_state=42
        )
        
        model = RandomForestClassifier(n_estimators=100, random_state=42)
        model.fit(X_train, y_train)
        
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        
        assert accuracy > 0.85, f'Model accuracy {accuracy} below threshold'
        
        print(f'âœ… Model training test passed! Accuracy: {accuracy:.4f}')
        "

  docker-build:
    name: Build and Test Docker Image
    runs-on: ubuntu-latest
    needs: test-pipeline
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2
    
    - name: Create Dockerfile if not exists
      run: |
        if [ ! -f Dockerfile ]; then
          cat > Dockerfile << 'EOF'
        FROM apache/airflow:2.7.3-python3.10
        USER airflow
        RUN pip install --no-cache-dir pandas scikit-learn numpy
        USER airflow
        EOF
        fi
    
    - name: Build Docker image
      run: |
        docker build -t airflow-ml-pipeline:test .
    
    - name: Test Docker image
      run: |
        docker run --rm airflow-ml-pipeline:test python -c "
        import pandas as pd
        import sklearn
        import numpy as np
        print('âœ… All packages installed successfully!')
        print(f'pandas: {pd.__version__}')
        print(f'sklearn: {sklearn.__version__}')
        print(f'numpy: {np.__version__}')
        "
    
    - name: Login to Docker Hub (only on main)
      if: github.ref == 'refs/heads/main' && github.event_name == 'push'
      uses: docker/login-action@v2
      with:
        username: ${{ secrets.DOCKER_USERNAME }}
        password: ${{ secrets.DOCKER_PASSWORD }}
    
    - name: Push to Docker Hub (only on main)
      if: github.ref == 'refs/heads/main' && github.event_name == 'push'
      run: |
        docker tag airflow-ml-pipeline:test ${{ secrets.DOCKER_USERNAME }}/airflow-ml-pipeline:latest
        docker tag airflow-ml-pipeline:test ${{ secrets.DOCKER_USERNAME }}/airflow-ml-pipeline:${{ github.sha }}
        docker push ${{ secrets.DOCKER_USERNAME }}/airflow-ml-pipeline:latest
        docker push ${{ secrets.DOCKER_USERNAME }}/airflow-ml-pipeline:${{ github.sha }}

  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: docker-build
    if: github.ref == 'refs/heads/develop'
    environment:
      name: staging
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Deploy to staging
      run: |
        echo "ðŸš€ Deploying to staging environment..."
        echo "âœ… Staging deployment completed!"
        # Add your staging deployment commands here

  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: docker-build
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    environment:
      name: production
      url: https://your-airflow-instance.com
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Deploy to production
      run: |
        echo "ðŸš€ Deploying to production environment..."
        echo "âœ… Production deployment completed!"
        # Add your production deployment commands here
        # Example: kubectl apply -f k8s/ or docker-compose up -d

  notify:
    name: Send Notifications
    runs-on: ubuntu-latest
    needs: [lint-and-test, test-pipeline, docker-build]
    if: always()
    
    steps:
    - name: Check status and notify
      run: |
        if [ "${{ needs.lint-and-test.result }}" == "success" ] && \
           [ "${{ needs.test-pipeline.result }}" == "success" ] && \
           [ "${{ needs.docker-build.result }}" == "success" ]; then
          echo "âœ… All CI/CD jobs passed successfully!"
          echo "ðŸ“§ Sending success notification..."
        else
          echo "âŒ Some CI/CD jobs failed!"
          echo "ðŸ“§ Sending failure notification..."
        fi