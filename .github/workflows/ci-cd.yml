name: Airflow ML Pipeline CI/CD

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  AIRFLOW_UID: 50000
  DOCKER_IMAGE: ${{ secrets.DOCKER_USERNAME }}/airflow-ml-pipeline

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Create .env file
        run: |
          echo "AIRFLOW_UID=${{ env.AIRFLOW_UID }}" > .env
          echo "_AIRFLOW_WWW_USER_USERNAME=airflow" >> .env
          echo "_AIRFLOW_WWW_USER_PASSWORD=airflow" >> .env

      - name: Create required directories
        run: |
          mkdir -p logs plugins data
          chmod -R 777 logs plugins data

      - name: Start services
        run: |
          docker-compose up -d postgres
          echo "Waiting for postgres..."
          sleep 15

      - name: Initialize Airflow
        run: |
          docker-compose run --rm airflow-init
          sleep 10

      - name: Validate DAGs
        run: |
          docker-compose run --rm airflow-webserver airflow dags list

      - name: Test DAG integrity
        run: |
          docker-compose run --rm airflow-webserver python -c "
          from airflow.models import DagBag
          import sys
          
          dagbag = DagBag('/opt/airflow/dags', include_examples=False)
          
          if dagbag.import_errors:
              print('‚ùå DAG Import Errors:')
              for filename, error in dagbag.import_errors.items():
                  print(f'\nFile: {filename}')
                  print(f'Error: {error}')
              sys.exit(1)
          
          if not dagbag.dags:
              print('‚ùå No DAGs found')
              sys.exit(1)
          
          print('\n‚úÖ DAG Validation Results:')
          for dag_id, dag in dagbag.dags.items():
              print(f'\nüìã DAG: {dag_id}')
              print(f'  Tasks: {dag.task_count}')
              for task in dag.tasks:
                  print(f'    - {task.task_id}')
          
          print('\n‚úÖ All DAGs validated successfully!')
          "

      - name: Cleanup
        if: always()
        run: docker-compose down -v

  build-and-push:
    needs: test
    runs-on: ubuntu-latest
    if: github.event_name == 'push'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: |
            ${{ env.DOCKER_IMAGE }}:latest
            ${{ env.DOCKER_IMAGE }}:${{ github.sha }}
          cache-from: type=registry,ref=${{ env.DOCKER_IMAGE }}:latest
          cache-to: type=inline

      - name: Test pushed image
        run: |
          docker pull ${{ env.DOCKER_IMAGE }}:latest
          docker run --rm ${{ env.DOCKER_IMAGE }}:latest airflow version

  integration-test:
    needs: build-and-push
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Log in to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Update docker-compose to use custom image
        run: |
          sed -i "s|image: apache/airflow:2.7.3-python3.10|image: ${{ env.DOCKER_IMAGE }}:latest|g" docker-compose.yml

      - name: Create .env file
        run: |
          echo "AIRFLOW_UID=${{ env.AIRFLOW_UID }}" > .env
          echo "_AIRFLOW_WWW_USER_USERNAME=airflow" >> .env
          echo "_AIRFLOW_WWW_USER_PASSWORD=airflow" >> .env

      - name: Create directories
        run: |
          mkdir -p logs plugins data
          chmod -R 777 logs plugins data

      - name: Pull custom image
        run: docker pull ${{ env.DOCKER_IMAGE }}:latest

      - name: Start full stack
        run: |
          docker-compose up -d
          echo "Waiting for services..."
          sleep 60

      - name: Check services
        run: |
          docker-compose ps
          echo "=== Webserver Logs ==="
          docker-compose logs airflow-webserver | tail -20
          echo "=== Scheduler Logs ==="
          docker-compose logs airflow-scheduler | tail -20

      - name: Wait for Airflow health
        run: |
          for i in {1..20}; do
            if curl -f http://localhost:8080/health; then
              echo "‚úÖ Airflow is healthy"
              exit 0
            fi
            echo "Attempt $i/20 - Waiting..."
            sleep 10
          done
          echo "‚ùå Airflow failed to start"
          docker-compose logs
          exit 1

      - name: List DAGs
        run: |
          docker-compose exec -T airflow-scheduler airflow dags list

      - name: Cleanup
        if: always()
        run: docker-compose down -v

  deploy:
    needs: integration-test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    steps:
      - name: Deployment Summary
        run: |
          echo "üöÄ Deployment Summary"
          echo "===================="
          echo "‚úÖ Tests Passed"
          echo "‚úÖ Docker Image Built & Pushed"
          echo "‚úÖ Integration Tests Passed"
          echo ""
          echo "üì¶ Image: ${{ env.DOCKER_IMAGE }}:latest"
          echo "üì¶ Image: ${{ env.DOCKER_IMAGE }}:${{ github.sha }}"
          echo ""
          echo "üéØ Ready for production deployment"